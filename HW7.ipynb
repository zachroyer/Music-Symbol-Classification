{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zachroyer/Music-Symbol-Classification/blob/main/HW7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "w_R6GCqTCkVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d6549ad-91fd-4ec4-d6de-c5f6a0c00571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "#@title Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set device (use GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtVVL_TuCkVo"
      },
      "source": [
        "# Part 1: Load/Analyze Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##What is your dataset? Please describe your dataset and where you got it"
      ],
      "metadata": {
        "id": "dbvdzOIUbJY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "My dataset of choice is titled \"Music Notes Dataset\". I obtained it on Kaggle uploaded by a user 'kishanj'.\n",
        "\n",
        "## Description of Music Notes Dataset\n",
        "This dataset contains a large set of one category of notes one might encounter while examining sheet music.\n",
        "\n",
        "One image can correspond to the following labels:\n",
        "*  Whole\n",
        "*  Half\n",
        "*  Quarter\n",
        "*  Eighth\n",
        "*  Sixteenth\n",
        "\n",
        "Each note can be broken down in to three components (or a lack of one or more):\n",
        "1.   Note Head\n",
        "2.   Stem\n",
        "3.   Flag\n",
        "\n",
        "INSERT IMAGE\n",
        "\n",
        "The change of these components is what determines how *long* a note is held for when playing it. The placement of the note determines *which* note to play on your desired instrument. This dataset omits that implicit feature by isolating the images to the features of a note, not its placement.\n",
        "\n",
        "The Note Head is the circular portion of the note.\n",
        "The Stem is the thin line that grows from the Note Head.\n",
        "The Flag is the perpindicular tail on the end of a Stem.\n",
        "\n",
        "# Self-Collected Test Data\n",
        "In addition to the dataset from Kaggle, I also collected a small sample of test data myself. The data came from a digital scan of a physical copy of Minuet in D Minor (J.S. Bach) from the Schirmer's Library of Musical Classics Vol. 2066. This is a piece that I have personally studied on the piano.\n",
        "\n",
        "With that digital scan,\n"
      ],
      "metadata": {
        "id": "hOBVcBmbb9iu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load your dataset / Implement your dataloader"
      ],
      "metadata": {
        "id": "2THiVIuNbmkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing dataset directly from Kaggle\n",
        "!pip install kagglehub\n",
        "\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"kishanj/music-notes-datasets\")\n",
        "print(\"Downloaded to: \", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A_OYgygCksT",
        "outputId": "88b42f19-7e31-43f8-d2e0-8458eb13214e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.11.12)\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/kishanj/music-notes-datasets?dataset_version_number=4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12.0M/12.0M [00:01<00:00, 12.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded to:  /root/.cache/kagglehub/datasets/kishanj/music-notes-datasets/versions/4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a Transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels = 1), # Guaranteeing only one color channel for efficiency\n",
        "    transforms.Resize((64,64)), # Resizing image\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,),(0.5)), # Normalizing pixel values to range from (0,1) and (-1,1) for stability\n",
        "])\n",
        "\n",
        "data = torchvision.datasets.ImageFolder(root=path, transform=transform) # Easily extract class information for data from directory structure using ImageFolder\n",
        "print(len(data))"
      ],
      "metadata": {
        "id": "rZuivL4ab_e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91a58bd5-84a7-479f-d3a6-1cede1c1cc1a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting Data into random train, validation and test splits\n",
        "train_split, val_split, test_split = torch.utils.data.random_split(data, [int(len(data)*0.8), int(len(data)*0.1), int(len(data)*0.1)])\n",
        "\n",
        "# Wrapping random data in DataLoader for PyTorch\n",
        "train_loader = DataLoader(train_split)\n",
        "validation_loader = DataLoader(val_split)\n",
        "test_loader = DataLoader(test_split)"
      ],
      "metadata": {
        "id": "IO2Whw_oMHEa"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset Analyis Statistics"
      ],
      "metadata": {
        "id": "ZR15EWtpcGDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - code for collecting statistics from your dataset / plots and analysis\n",
        "train_iter = iter(train_loader)\n",
        "print(f\"Number of data points (images) in each split (train/val/test): {len(train_loader)}/{len(validation_loader)}/{len(test_loader)}\")\n",
        "print(f\"\")\n",
        "\n",
        "A description of the dataset\n",
        "● Format of the inputs and outputs\n",
        "● Number of examples in the train/val/test splits\n",
        "● A visualization of at least 5 examples from your dataset\n",
        "Summary statistics (e.g. for language datasets, you might include things such as the average lengths\n",
        "of the inputs or the number of unique words).\n",
        "● If possible, any visualizations of the dataset statistics."
      ],
      "metadata": {
        "id": "WxFU7WRScJTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11908796-dd76-47b5-d091-fd9cb6fcdc1c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data points (images) in each split (train/val/test): 4000/500/500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis\n",
        "\n",
        "\n",
        "## Format\n"
      ],
      "metadata": {
        "id": "Mk8kMwR-cNL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Literature Review"
      ],
      "metadata": {
        "id": "1EmxVzkHhtvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO - Follow instructions in the assignment for your literature review\n",
        "\n",
        "\n",
        "https://ieeexplore.ieee.org/document/8270207 (Accessible via University of Utah login)"
      ],
      "metadata": {
        "id": "ZBxv3M_RcUIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Implement networks in PyTorch"
      ],
      "metadata": {
        "id": "RKQ_C71ThwqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note of warning here: Depending on how easily you can allocate GPU resources, you may want to make your network much shallower so that you can train it more easily\n",
        "Aim to have one gradient update take no more than a few seconds\n",
        "May also want to reduce the number of training steps if training is too slow"
      ],
      "metadata": {
        "id": "X5JKyDsNh9CP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - implement your PyTorch Module\n"
      ],
      "metadata": {
        "id": "Le5pnYqaclJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - implement your training loop"
      ],
      "metadata": {
        "id": "72d14EfbcoCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - plot train and validation accuracy of your model during training"
      ],
      "metadata": {
        "id": "AJ1m877lcqa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hint: look at earlier homeworks / resuse code from those to help you here"
      ],
      "metadata": {
        "id": "cj7BrJ6wcvI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4: Run Hyperparameter Experiments"
      ],
      "metadata": {
        "id": "HpqXry-Sh2O4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - perform hyperparameter grid searches and plot accuracies"
      ],
      "metadata": {
        "id": "0UO4tkRhc6sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - perform other experiments and plot accuracies"
      ],
      "metadata": {
        "id": "esd0YWZQc9uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - calculate the final test accuracy"
      ],
      "metadata": {
        "id": "risBZpbLdImE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO - Explain your experiments above. See assignment doc for more details."
      ],
      "metadata": {
        "id": "TVXiqisoiR_r"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}